{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7513bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 01:12:43,728 - __init__.py - wrapper - DEBUG - matplotlib data path: d:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\.eegnetenv\\Lib\\site-packages\\matplotlib\\mpl-data\n",
      "2026-01-27 01:12:43,735 - __init__.py - wrapper - DEBUG - CONFIGDIR=C:\\Users\\Kseniia Dubivka\\.matplotlib\n",
      "2026-01-27 01:12:43,760 - __init__.py - <module> - DEBUG - interactive is False\n",
      "2026-01-27 01:12:43,761 - __init__.py - <module> - DEBUG - platform is win32\n",
      "2026-01-27 01:12:43,797 - __init__.py - wrapper - DEBUG - CACHEDIR=C:\\Users\\Kseniia Dubivka\\.matplotlib\n",
      "2026-01-27 01:12:43,802 - font_manager.py - _load_fontmanager - DEBUG - Using fontManager instance from C:\\Users\\Kseniia Dubivka\\.matplotlib\\fontlist-v390.json\n",
      "2026-01-27 01:12:45,482 - __init__.py - <module> - DEBUG - Creating converter from 7 to 5\n",
      "2026-01-27 01:12:45,482 - __init__.py - <module> - DEBUG - Creating converter from 5 to 7\n",
      "2026-01-27 01:12:45,483 - __init__.py - <module> - DEBUG - Creating converter from 7 to 5\n",
      "2026-01-27 01:12:45,484 - __init__.py - <module> - DEBUG - Creating converter from 5 to 7\n",
      "2026-01-27 01:12:45,693 - base.py - __new__ - DEBUG - No description found for dataset BaseDataset. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,695 - base.py - __new__ - DEBUG - No description found for dataset BaseBIDSDataset. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,696 - base.py - __new__ - DEBUG - No description found for dataset LocalBIDSDataset. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,697 - base.py - __new__ - DEBUG - No description found for dataset CompoundDataset. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,701 - base.py - __new__ - DEBUG - No description found for dataset bi2012. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,702 - base.py - __new__ - DEBUG - No description found for dataset bi2013a. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,704 - base.py - __new__ - DEBUG - No description found for dataset bi2014a. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,705 - base.py - __new__ - DEBUG - No description found for dataset bi2014b. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,707 - base.py - __new__ - DEBUG - No description found for dataset bi2015a. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,709 - base.py - __new__ - DEBUG - No description found for dataset bi2015b. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,713 - base.py - __new__ - DEBUG - No description found for dataset VirtualReality. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,715 - base.py - __new__ - DEBUG - No description found for dataset _base_bi_il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,716 - base.py - __new__ - DEBUG - No description found for dataset BI2014a_Il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,717 - base.py - __new__ - DEBUG - No description found for dataset bi2014a_il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,718 - base.py - __new__ - DEBUG - No description found for dataset BI2014b_Il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,719 - base.py - __new__ - DEBUG - No description found for dataset bi2014b_il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,720 - base.py - __new__ - DEBUG - No description found for dataset BI2015a_Il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,721 - base.py - __new__ - DEBUG - No description found for dataset bi2015a_il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,722 - base.py - __new__ - DEBUG - No description found for dataset BI2015b_Il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,723 - base.py - __new__ - DEBUG - No description found for dataset bi2015b_il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,724 - base.py - __new__ - DEBUG - No description found for dataset Cattan2019_VR_Il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,725 - base.py - __new__ - DEBUG - No description found for dataset VirtualReality_il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,726 - base.py - __new__ - DEBUG - No description found for dataset BI_Il. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,727 - base.py - __new__ - DEBUG - No description found for dataset biIlliteracy. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,736 - base.py - __new__ - DEBUG - No description found for dataset BaseShin2017. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,746 - base.py - __new__ - DEBUG - No description found for dataset MNEBNCI. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,750 - base.py - __new__ - DEBUG - No description found for dataset BNCI2014001. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,752 - base.py - __new__ - DEBUG - No description found for dataset BNCI2014002. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,754 - base.py - __new__ - DEBUG - No description found for dataset BNCI2014004. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,755 - base.py - __new__ - DEBUG - No description found for dataset BNCI2014008. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,757 - base.py - __new__ - DEBUG - No description found for dataset BNCI2014009. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,759 - base.py - __new__ - DEBUG - No description found for dataset BNCI2015001. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,761 - base.py - __new__ - DEBUG - No description found for dataset BNCI2015003. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,762 - base.py - __new__ - DEBUG - No description found for dataset BNCI2015004. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,767 - base.py - __new__ - DEBUG - No description found for dataset BaseCastillos2023. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,771 - base.py - __new__ - DEBUG - No description found for dataset _Dreyer2023Base. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,776 - base.py - __new__ - DEBUG - No description found for dataset ErpCore2021. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,782 - base.py - __new__ - DEBUG - No description found for dataset FakeDataset. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,783 - base.py - __new__ - DEBUG - No description found for dataset FakeVirtualRealityDataset. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,788 - base.py - __new__ - DEBUG - No description found for dataset _BaseVisualMatrixSpellerDataset. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,794 - base.py - __new__ - DEBUG - No description found for dataset Lee2019. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,801 - base.py - __new__ - DEBUG - No description found for dataset MunichMI. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,805 - base.py - __new__ - DEBUG - No description found for dataset HeadMountedDisplay. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,814 - base.py - __new__ - DEBUG - No description found for dataset SSVEPExo. Complete the appropriate moabb/datasets/summary_*.csv file\n",
      "2026-01-27 01:12:45,818 - base.py - __new__ - DEBUG - No description found for dataset BaseMAMEM. Complete the appropriate moabb/datasets/summary_*.csv file\n"
     ]
    }
   ],
   "source": [
    "from scipy import io\n",
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from eegnet_repl.config import Paths\n",
    "from eegnet_repl.dataset import build_dataset_from_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9dd08d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\true_labels\\A01T.mat\n",
      "A01T\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "paths = Paths.from_here()\n",
    "root = paths.project_root\n",
    "filename = root / f'true_labels/A01T.mat'\n",
    "\n",
    "\n",
    "print(filename)\n",
    "print(os.path.basename(os.path.normpath(filename))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ff418",
   "metadata": {},
   "source": [
    "## Check if labels are the same for A0nT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98111128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:12:35,329 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:35,330 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A01T-preprocessed.fif...\n",
      "    Range : 0 ... 344333 =      0.000 ...  2690.102 secs\n",
      "Ready.\n",
      "Reading 0 ... 344333  =      0.000 ...  2690.102 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A01T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:12:35,569 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:35,570 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A02T-preprocessed.fif...\n",
      "    Range : 0 ... 346710 =      0.000 ...  2708.672 secs\n",
      "Ready.\n",
      "Reading 0 ... 346710  =      0.000 ...  2708.672 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A02T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:12:35,830 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:35,831 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A03T-preprocessed.fif...\n",
      "    Range : 0 ... 338190 =      0.000 ...  2642.109 secs\n",
      "Ready.\n",
      "Reading 0 ... 338190  =      0.000 ...  2642.109 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A03T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n",
      "2026-01-26 22:12:36,059 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:36,060 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A05T-preprocessed.fif...\n",
      "    Range : 0 ... 351292 =      0.000 ...  2744.469 secs\n",
      "Ready.\n",
      "Reading 0 ... 351292  =      0.000 ...  2744.469 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A05T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:12:36,320 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:36,321 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A06T-preprocessed.fif...\n",
      "    Range : 0 ... 347637 =      0.000 ...  2715.914 secs\n",
      "Ready.\n",
      "Reading 0 ... 347637  =      0.000 ...  2715.914 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A06T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:12:36,562 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:36,563 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A07T-preprocessed.fif...\n",
      "    Range : 0 ... 348707 =      0.000 ...  2724.273 secs\n",
      "Ready.\n",
      "Reading 0 ... 348707  =      0.000 ...  2724.273 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A07T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:12:36,864 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:36,864 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A08T-preprocessed.fif...\n",
      "    Range : 0 ... 345737 =      0.000 ...  2701.070 secs\n",
      "Ready.\n",
      "Reading 0 ... 345737  =      0.000 ...  2701.070 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A08T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:12:37,114 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:12:37,116 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A09T-preprocessed.fif...\n",
      "    Range : 0 ... 344743 =      0.000 ...  2693.305 secs\n",
      "Ready.\n",
      "Reading 0 ... 344743  =      0.000 ...  2693.305 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A09T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Labels from true_labels files match the labels from build_dataset_from_preprocessed: True\n"
     ]
    }
   ],
   "source": [
    "paths = Paths.from_here()\n",
    "root = paths.project_root\n",
    "same = True\n",
    "for i in range(1,10):\n",
    "    if i == 4:\n",
    "        continue\n",
    "    filename = root / f'true_labels/A0{i}T.mat'\n",
    "    labels = io.loadmat(file_name=filename, squeeze_me=True)\n",
    "    labels = labels['classlabel']\n",
    "    train_data = build_dataset_from_preprocessed(src='kaggle', subject=i, type='Train')\n",
    "    train_labels = train_data.y\n",
    "    new_labels = np.zeros_like(train_labels)\n",
    "    new_labels[train_labels == 7] = 1\n",
    "    new_labels[train_labels == 8] = 2\n",
    "    new_labels[train_labels == 9] = 3\n",
    "    new_labels[train_labels == 10] = 4\n",
    "    same = same and np.allclose(new_labels, labels)\n",
    "\n",
    "print(f'Labels from true_labels files match the labels from build_dataset_from_preprocessed: {same}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f023d7",
   "metadata": {},
   "source": [
    "## Subject 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb910381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 22:03:28,837 - dataset.py - build_dataset_from_preprocessed - INFO - Building dataset from preprocessed data in D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\n",
      "2026-01-26 22:03:28,839 - dataset.py - build_dataset_from_preprocessed - INFO - Found 1 preprocessed files for subject 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A04T-preprocessed.fif...\n",
      "    Range : 0 ... 307667 =      0.000 ...  2403.648 secs\n",
      "Ready.\n",
      "Reading 0 ... 307667  =      0.000 ...  2403.648 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\src\\eegnet_repl\\dataset.py:164: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A04T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 144 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "filename = root / f'true_labels/A04T.mat'\n",
    "labels = io.loadmat(file_name=filename, squeeze_me=True)\n",
    "labels = labels['classlabel']\n",
    "train_data = build_dataset_from_preprocessed(src='kaggle', subject=4, type='Train')\n",
    "train_labels = train_data.y\n",
    "new_labels = np.zeros_like(train_labels)\n",
    "new_labels[train_labels == 7] = 1\n",
    "new_labels[train_labels == 8] = 2\n",
    "new_labels[train_labels == 9] = 3\n",
    "new_labels[train_labels == 10] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4eddc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddf3e224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55f0c51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.uint8(1), np.uint8(2), np.uint8(3), np.uint8(4)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af805868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(7), np.int64(8)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5d6113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(1), np.int64(2)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d315c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A04T-preprocessed.fif...\n",
      "    Range : 0 ... 307667 =      0.000 ...  2403.648 secs\n",
      "Ready.\n",
      "Reading 0 ... 307667  =      0.000 ...  2403.648 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kseniia Dubivka\\AppData\\Local\\Temp\\ipykernel_20384\\296160867.py:2: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Train\\A04T-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  s4 = mne.io.read_raw_fif(s4_filename, preload=True)\n"
     ]
    }
   ],
   "source": [
    "s4_filename = root / 'data/processed/Train/A04T-preprocessed.fif'\n",
    "s4 = mne.io.read_raw_fif(s4_filename, preload=True)\n",
    "# create a plot of annotation descriptions over time\n",
    "annotationsT = s4.annotations.description\n",
    "\n",
    "# Annotation conversion map\n",
    "annotation_map = {\n",
    "                '276': 'Idling EEG (eyes open)',\n",
    "                '277': 'Idling EEG (eyes closed)',\n",
    "                '768': 'Start of a trial',\n",
    "                '769': 'Cue onset left (class 1)',\n",
    "                '770': 'Cue onset right (class 2)',\n",
    "                '771': 'Cue onset foot (class 3)',\n",
    "                '772': 'Cue onset tongue (class 4)',\n",
    "                '783': 'Cue unknown',\n",
    "                '1023': 'Rejected trial',\n",
    "                '1072': 'Eye movements',\n",
    "                '32766': 'Start of a new run',\n",
    "                }\n",
    "# Map the annotations to their descriptions\n",
    "annotationsT = [annotation_map.get(desc, desc) for desc in annotationsT]\n",
    "eventsT, event_idT = mne.events_from_annotations(s4)\n",
    "\n",
    "# Replace event IDs with annotation descriptions\n",
    "event_idT = {annotation_map.get(str(key), str(key)): value for key, value in event_idT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa765602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: Rejected trial, event ID: 1\n",
      "Event: Eye movements, event ID: 2\n",
      "Event: Start of a new run, event ID: 3\n",
      "Event: Start of a trial, event ID: 4\n",
      "Event: Cue onset left (class 1), event ID: 5\n",
      "Event: Cue onset right (class 2), event ID: 6\n",
      "Event: Cue onset foot (class 3), event ID: 7\n",
      "Event: Cue onset tongue (class 4), event ID: 8\n"
     ]
    }
   ],
   "source": [
    "for event, id in event_idT.items():\n",
    "    print(f'Event: {event}, event ID: {id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbda4ab",
   "metadata": {},
   "source": [
    "## Mapping labels to A0nE files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b943a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filename = root / 'true_labels/A01E.mat'\n",
    "#data_filename = root / 'data/processed/Train/A04T-preprocessed.fif'\n",
    "data_filename = root / 'data/processed/Eval/A01E-preprocessed.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9afb6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = io.loadmat(file_name=labels_filename, squeeze_me=True)\n",
    "labels = labels['classlabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dd1a2404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Eval\\A01E-preprocessed.fif...\n",
      "    Range : 0 ... 351743 =      0.000 ...  2747.992 secs\n",
      "Ready.\n",
      "Reading 0 ... 351743  =      0.000 ...  2747.992 secs...\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "Event: Rejected trial, event ID: 1\n",
      "Event: Eye movements, event ID: 2\n",
      "Event: Idling EEG (eyes open), event ID: 3\n",
      "Event: Idling EEG (eyes closed), event ID: 4\n",
      "Event: Start of a new run, event ID: 5\n",
      "Event: Start of a trial, event ID: 6\n",
      "Event: Cue unknown, event ID: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kseniia Dubivka\\AppData\\Local\\Temp\\ipykernel_20384\\2213508069.py:1: RuntimeWarning: This filename (D:\\!Studying\\NeuroData\\DS_n_advanced_python\\HW\\Final_project_DS\\code\\EEGNetReplication\\data\\processed\\Eval\\A01E-preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  pp = mne.io.read_raw_fif(data_filename, preload=True)\n"
     ]
    }
   ],
   "source": [
    "pp = mne.io.read_raw_fif(data_filename, preload=True)\n",
    "# create a plot of annotation descriptions over time\n",
    "annotationsT = pp.annotations.description\n",
    "\n",
    "# Annotation conversion map\n",
    "annotation_map = {\n",
    "                '276': 'Idling EEG (eyes open)',\n",
    "                '277': 'Idling EEG (eyes closed)',\n",
    "                '768': 'Start of a trial',\n",
    "                '769': 'Cue onset left (class 1)',\n",
    "                '770': 'Cue onset right (class 2)',\n",
    "                '771': 'Cue onset foot (class 3)',\n",
    "                '772': 'Cue onset tongue (class 4)',\n",
    "                '783': 'Cue unknown',\n",
    "                '1023': 'Rejected trial',\n",
    "                '1072': 'Eye movements',\n",
    "                '32766': 'Start of a new run',\n",
    "                }\n",
    "# Map the annotations to their descriptions\n",
    "annotationsT = [annotation_map.get(desc, desc) for desc in annotationsT]\n",
    "eventsT, event_idT = mne.events_from_annotations(pp)\n",
    "\n",
    "# Replace event IDs with annotation descriptions\n",
    "event_idT = {annotation_map.get(str(key), str(key)): value for key, value in event_idT.items()}\n",
    "\n",
    "for event, id in event_idT.items():\n",
    "    print(f'Event: {event}, event ID: {id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b8e87596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 257 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "all_labels = []\n",
    "all_event_ids = {'Cue unknown': 7}\n",
    "\n",
    "epocsT_std = mne.Epochs(pp, eventsT, event_id=all_event_ids,\n",
    "                    tmin=0.5, tmax=2.5, baseline=None, preload=True)\n",
    "\n",
    "all_data.append(epocsT_std.get_data())  # Shape: (n_epochs, n_channels, n_times)\n",
    "all_labels.append(epocsT_std.events[:, -1])  # Extract labels from events\n",
    "\n",
    "X = np.concatenate(all_data, axis=0)\n",
    "y = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0b255fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(epocsT_std.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d5c2af58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(epocsT_std.events[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fe151818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 257)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ad57a78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b33a0ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdcab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels # 1 2 3 4 instead of 7 8 9 10\n",
    "# probably better to fix everything to 0 1 2 3 during build dataset func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2a39d",
   "metadata": {},
   "source": [
    "## build_dataset_from_preprocessed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "05a4d776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  7  9  8 10]\n",
      "{7: 0, 8: 1, 9: 2, 10: 3}\n",
      "[0 0 2 1 3]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([7,7,9,8,10])\n",
    "print(labels)\n",
    "map = dict([(7,0),(8,1),(9,2),(10,3)])\n",
    "print(map)\n",
    "new_labels = np.zeros_like(labels)\n",
    "for old, new in map.items():\n",
    "    new_labels[labels == old] = new\n",
    "print(new_labels)\n",
    "print(set(new_labels).issubset(set(map.values())))\n",
    "print(set(map.values())==set(new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(labels,map): # -> np.ndarray\n",
    "\n",
    "    new_labels = np.zeros_like(labels)\n",
    "    for old_label, new_label in map.items():\n",
    "        new_labels[labels == old_label] = new_label\n",
    "\n",
    "    if not set(new_labels).issubset(set(map.values())):\n",
    "        raise RuntimeError(f\"Not all labels were mapped.\")\n",
    "    \n",
    "    if not set(map.values())==set(new_labels):\n",
    "        logger.warning(f\"Some classes are missing from the labels.\")\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a7a720cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_data_into_epochs(file,mode='Train'):\n",
    "\n",
    "    paths = Paths.from_here()\n",
    "    root = paths.project_root\n",
    "    \n",
    "    pp = mne.io.read_raw_fif(file, preload=True)\n",
    "    # create a plot of annotation descriptions over time\n",
    "    annotationsT = pp.annotations.description\n",
    "\n",
    "    # Annotation conversion map\n",
    "    annotation_map = {\n",
    "        '276': 'Idling EEG (eyes open)',\n",
    "        '277': 'Idling EEG (eyes closed)',\n",
    "        '768': 'Start of a trial',\n",
    "        '769': 'Cue onset left (class 1)',\n",
    "        '770': 'Cue onset right (class 2)',\n",
    "        '771': 'Cue onset foot (class 3)',\n",
    "        '772': 'Cue onset tongue (class 4)',\n",
    "        '783': 'Cue unknown',\n",
    "        '1023': 'Rejected trial',\n",
    "        '1072': 'Eye movements',\n",
    "        '32766': 'Start of a new run',\n",
    "    }\n",
    "\n",
    "    # Map the annotations to their descriptions\n",
    "    annotationsT = [annotation_map.get(desc, desc) for desc in annotationsT]\n",
    "    eventsT, event_idT = mne.events_from_annotations(pp)\n",
    "\n",
    "    # Replace event IDs with annotation descriptions\n",
    "    event_idT = {annotation_map.get(str(key), str(key)): value for key, value in event_idT.items()}\n",
    "\n",
    "    # Break the data into trial windows (0.5-2.5 seconds cue onset) using cue onset markers\n",
    "    if mode == 'Train':\n",
    "        if '4' not in file:        \n",
    "            all_event_ids = {'Cue onset left (class 1)': 7,\n",
    "                                'Cue onset right (class 2)': 8,\n",
    "                                'Cue onset foot (class 3)': 9,\n",
    "                                'Cue onset tongue (class 4)': 10}\n",
    "            map = dict([(7,0),(8,1),(9,2),(10,3)])\n",
    "        else:\n",
    "            all_event_ids = {'Cue onset left (class 1)': 5,\n",
    "                                'Cue onset right (class 2)': 6,\n",
    "                                'Cue onset foot (class 3)': 7,\n",
    "                                'Cue onset tongue (class 4)': 8}\n",
    "            map = dict([(5,0),(6,1),(7,2),(8,3)])\n",
    "    elif mode == 'Eval':\n",
    "        all_event_ids = {'Cue unknown': 7}\n",
    "        map = dict([(1,0),(2,1),(3,2),(4,3)])\n",
    "    else: \n",
    "        raise ValueError(f\"Unknown trainig mode: {mode}\")\n",
    "\n",
    "    # Filter to only include events that exist in this file\n",
    "    available_event_ids = {event_name: event_id for event_name, event_id in all_event_ids.items() \n",
    "                            if event_id in event_idT.values()}\n",
    "    \n",
    "    epocsT_std = mne.Epochs(pp, eventsT, event_id=available_event_ids,\n",
    "                            tmin=0.5, tmax=2.5, baseline=None, preload=True)\n",
    "    \n",
    "    data = epocsT_std.get_data()\n",
    "    labels = epocsT_std.events[:, -1]\n",
    "\n",
    "    if mode == 'Eval':\n",
    "        filename = root / f'true_labels/{file[:4]}.mat'\n",
    "        labels = io.loadmat(file_name=filename, squeeze_me=True)\n",
    "        labels = labels['classlabel']\n",
    "    \n",
    "    labels = map_labels(labels=labels, map=map)\n",
    "\n",
    "    return data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_from_preprocessed_2(src='kaggle', subject='all', mode='Train') -> BCICI2ADataset:\n",
    "    '''\n",
    "    Build a Dataset object from preprocessed EEG data files in dest_path.\n",
    "    \n",
    "    Args:\n",
    "        src: Source of the dataset ('kaggle' or 'moabb').\n",
    "        subject: Subject identifier [1-9] (default is 'all' to include all subjects).\n",
    "        type: Whether to use training or testing data for the dataset ('Train' or 'Eval')\n",
    "\n",
    "    Returns:\n",
    "        Dataset object containing the data and metadata.\n",
    "    '''\n",
    "    paths = Paths.from_here()\n",
    "    if src == 'kaggle':\n",
    "        dest_path = paths.data_processed / mode\n",
    "    elif src == 'moabb':\n",
    "        dest_path = paths.data_moabb_processed / mode\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown source: {src}\")\n",
    "    logger.info(f\"Building dataset from preprocessed data in {dest_path}\")\n",
    "\n",
    "    if subject != 'all':\n",
    "        # Filter files for the specified subject\n",
    "        files = list(dest_path.glob(f\"A{subject:02d}{mode[0]}-preprocessed.fif\"))\n",
    "    else:\n",
    "        # Include all preprocessed files\n",
    "        files = list(dest_path.glob(\"*-preprocessed.fif\"))\n",
    "    if not files:\n",
    "        raise ValueError(f\"No preprocessed files found in {dest_path} for subject {subject}\")\n",
    "    logger.info(f\"Found {len(files)} preprocessed files for subject {subject}\")\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for file in files:\n",
    "\n",
    "        data, labels = break_data_into_epochs(file,mode=mode)\n",
    "\n",
    "        all_data.append(data)  # Shape: (n_epochs, n_channels, n_times)\n",
    "        all_labels.append(labels)  # Extract labels from events\n",
    "\n",
    "    X = np.concatenate(all_data, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return BCICI2ADataset(X=X, y=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eegnetenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
